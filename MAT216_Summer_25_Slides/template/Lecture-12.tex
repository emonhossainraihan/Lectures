\documentclass[11pt]{beamer}
\usepackage{amsfonts,amsmath,amsthm,amssymb}
\theoremstyle{plain}
\newtheorem{conjecture}{Conjecture}[section]
\usepackage{mathtools,mathptmx,listings,forest,enumitem}
\usepackage{graphicx}
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
% plotting things
\usepackage{graphicx}
\graphicspath{{images/}}
\usepackage{tikz-cd}
\pgfplotsset{compat=1.15}
\usepackage[
	backend=biber,
	style=verbose,
	sorting=ynt
]{biblatex}
\addbibresource{references.bib}
\usetheme{Madrid}
\usepackage{float,mathtools,dirtytalk,ulem,csquotes,cancel,hyperref}
\author[] % (optional)
{Emon Hossain\inst{1}}

\institute[University of Dhaka] % (optional)
{
  \inst{1}%
  Lecturer\\MNS department\\Brac University
}

\date[] % (optional)
{\textsc{Lecture-12}}


\title[]{MAT216: Linear Algebra and Fourier Transformation}

\setbeamertemplate{navigation symbols}{}


\AtBeginSection[]
{
  \begin{frame}
    \frametitle{Table of Contents}
    \tableofcontents[currentsection]
  \end{frame}
}

\usepackage{Kyushu}

% \usetheme{Frankfurt}

\begin{document}
\begin{frame}
\titlepage
\end{frame}

\begin{frame}{Orthogonal Set}
    \begin{definition}
        $A$ set of vectors $\left\{\mathbf{v}_i \mid 1 \leq i \leq n\right\}$ is orthogonal if $\mathbf{v}_i \cdot \mathbf{v}_j=0$ whenever $i \neq j$ and orthonormal if $\mathbf{v}_i \cdot \mathbf{v}_j= \begin{cases}1 & i=j \\ 0 & i \neq j\end{cases}$.
    \end{definition}
    For ease of notation, we define the the Kronecker delta function $\delta_{i j}$ to be the discrete function $\delta_{i j}=\left\{\begin{array}{ll}1 & i=j \\ 0 & i \neq j\end{array}\right.$. The matrix associated with the Kronecker delta, $\left[\delta_{i j}\right]=I$.
Note that an orthonormal set is an orthogonal set of unit vectors.
\end{frame}

\begin{frame}{Orthogonal basis}
    \begin{definition}
        An Orthonormal Basis is an orthonormal set of vectors, which is also a basis.
    \end{definition}
    \begin{example}
        Suppose, we are given five points, $x_1=-2,x_2=-1,x_3=0,x_4=1$, and $x_5=2$. Show that $x\perp x^2$ where, 
        $$\langle P(x),Q(x) \rangle=\sum_{i=1}^5 P(x_i)Q(x_i)$$
    \end{example}
\end{frame}

\begin{frame}{Example}
    \begin{example}
        Show that, $S=\{1,\sin(x),\cos(x)\}$ is an orthogonal set where the inner product defined by,
        $$\langle p(x),q(x) \rangle=\int_{-\pi}^\pi p(x)q(x)dx$$
    \end{example}
\end{frame}

\begin{frame}{Projection}
    Suppose we wish to project the vector $(3,2,1)$ onto the vector $(1,2,3)$. Compute,
$$
\begin{aligned}
\operatorname{proj}_{(1,2,3)}((3,2,1))=\frac{\langle(3,2,1),(1,2,3)\rangle}{\langle(1,2,3),(1,2,3)\rangle}(1,2,3) & =\frac{3 \cdot 1+2 \cdot 2+1 \cdot 3}{1 \cdot 1+2 \cdot 2+3 \cdot 3}(1,2,3) \\
& =\frac{10}{14}(1,2,3)=\left(\frac{5}{7}, \frac{10}{7}, \frac{15}{7}\right)
\end{aligned}
$$
Let us double-check that the projection is orthogonal. That is $\vec{w}-\operatorname{proj}_{\vec{v}}(\vec{w})$ ought to be orthogonal to $\vec{v}$. That is,
$$
(3,2,1)-\operatorname{proj}_{(1,2,3)}((3,2,1))=\left(3-\frac{5}{7}, 2-\frac{10}{7}, 1-\frac{15}{7}\right)=\left(\frac{16}{7}, \frac{4}{7}, \frac{-8}{7}\right)
$$
ought to be orthogonal to $(1,2,3)$. 
\end{frame}

\begin{frame}{Example}
We compute the inner product, and we had better get zero:
$$
\left\langle\left(\frac{16}{7}, \frac{4}{7}, \frac{-8}{7}\right),(1,2,3)\right\rangle=\frac{16}{7} \cdot 1+\frac{4}{7} \cdot 2-\frac{8}{7} \cdot 3=0 .
$$
\begin{example}
    The vectors $(1,1)$ and $(1,-1)$ form an orthogonal basis of $\mathbb{R}^2$. Suppose we wish to represent $(3,4)$ in terms of this basis, that is, we wish to find $a_1$ and $a_2$ such that
$$
(3,4)=a_1(1,1)+a_2(1,-1)
$$
We compute:
$$
a_1=\frac{\langle(3,4),(1,1)\rangle}{\langle(1,1),(1,1)\rangle}=\frac{7}{2}, \quad a_2=\frac{\langle(3,4),(1,-1)\rangle}{\langle(1,-1),(1,-1)\rangle}=\frac{-1}{2} .
$$
$$
(3,4)=\frac{7}{2}(1,1)+\frac{-1}{2}(1,-1)
$$
\end{example}
\end{frame}

\begin{frame}{Example}
    \begin{example}
        The vectors $(1,2,3)$ and $(3,0,-1)$ are orthogonal, and so they are an orthogonal basis of a subspace $S$ :
$$
S=\operatorname{span}\{(1,2,3),(3,0,-1)\}
$$
Let us find the vector in $S$ that is closest to $(2,1,0)$. That is, let us find $\operatorname{proj}_S((2,1,0))$.
$$
\begin{aligned}
\operatorname{proj}_S((2,1,0)) & =\frac{\langle(2,1,0),(1,2,3)\rangle}{\langle(1,2,3),(1,2,3)\rangle}(1,2,3)+\frac{\langle(2,1,0),(3,0,-1)\rangle}{\langle(3,0,-1),(3,0,-1)\rangle}(3,0,-1) \\
& =\frac{2}{7}(1,2,3)+\frac{3}{5}(3,0,-1) \\
& =\left(\frac{73}{35}, \frac{4}{7}, \frac{9}{35}\right)
\end{aligned}
$$
    \end{example}
\end{frame}

\begin{frame}{Gram-Schmidt Process}
    (Gram-Schmidt). If $\left\{\mathbf{x}_1, \ldots, \mathbf{x}_p\right\}$ is a linearly independent list of vectors in $W$, then there exists an orthogonal list $\left\{\mathbf{v}_1, \ldots, \mathbf{v}_p\right\}$ of vectors in $W$ such that
    $$
    \operatorname{Span}\left\{\mathbf{x}_1, \ldots, \mathbf{x}_j\right\}=\operatorname{Span}\left\{\mathbf{v}_1, \ldots, \mathbf{v}_j\right\}
    $$
for $j=1, \ldots, p$. More specifically,
$$
\begin{aligned}
\mathbf{v}_1 & =\mathbf{x}_1 \\
\mathbf{v}_2 & =\mathbf{x}_2-\frac{\left\langle\mathbf{x}_2, \mathbf{v}_1\right\rangle}{\left\langle\mathbf{v}_1, \mathbf{v}_1\right\rangle} \mathbf{v}_1 \\
\mathbf{v}_3 & =\mathbf{x}_3-\frac{\left\langle\mathbf{x}_3, \mathbf{v}_1\right\rangle}{\left\langle\mathbf{v}_1, \mathbf{v}_1\right\rangle} \mathbf{v}_1-\frac{\left\langle\mathbf{x}_3, \mathbf{v}_2\right\rangle}{\left\langle\mathbf{v}_2, \mathbf{v}_2\right\rangle} \mathbf{v}_2 \\
& \vdots \\
\mathbf{v}_p & =\mathbf{x}_p-\frac{\left\langle\mathbf{x}_p, \mathbf{v}_1\right\rangle}{\left\langle\mathbf{v}_1, \mathbf{v}_1\right\rangle} \mathbf{v}_1-\frac{\left\langle\mathbf{x}_p, \mathbf{v}_2\right\rangle}{\left\langle\mathbf{v}_2, \mathbf{v}_2\right\rangle} \mathbf{v}_2-\cdots-\frac{\left\langle\mathbf{x}_p, \mathbf{v}_{p-1}\right\rangle}{\left\langle\mathbf{v}_{p-1}, \mathbf{v}_{p-1}\right\rangle} \mathbf{v}_{p-1}
\end{aligned}
$$
\end{frame}

\begin{frame}{Gram-Schmidt Process}
Then $\left\{\mathbf{v}_1, \ldots, \mathbf{v}_p\right\}$ is an orthogonal basis for $V$. Normalizing each $\mathbf{v}_j$ results in an orthonormal basis.\\~\\
We can write this in compact notation by,
\begin{align*}
    v_1&=x_1\\
    v_k&=x_k-\sum_{i=2}^{k-1}\operatorname{Proj}_{v_i}x_k\\
    &= x_k-\sum_{i=2}^{k-1}\frac{\langle x_k,v_i \rangle}{\langle v_i,v_i \rangle}v_i
\end{align*}
\end{frame}


\begin{frame}{Example}
    \begin{example}
        Assume that
$$
v_1=\left[\begin{array}{l}
1 \\
1 \\
1 \\
1
\end{array}\right], v_2=\left[\begin{array}{c}
1 \\
1 \\
-1 \\
-1
\end{array}\right], v_3=\left[\begin{array}{c}
0 \\
-1 \\
2 \\
1
\end{array}\right]
$$


Apply the Gram Schmidt process to $\{\mathrm{v} 1, \mathrm{v} 2, \mathrm{v} 3\}$.
    \end{example}
    For visualization: \url{https://www.geogebra.org/m/zjcz6grm}. 
    And for Fourier idea: \url{https://www.desmos.com/calculator/4bmaga18bg}. Reason of inner product: \url{https://math.stackexchange.com/questions/3491286}.
\end{frame}

\end{document}